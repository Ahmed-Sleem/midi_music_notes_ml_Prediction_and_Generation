{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#prerun"
      ],
      "metadata": {
        "id": "Y6gu5LGFUaLp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V781qwu4UU-z",
        "outputId": "a446d6e7-510b-4a14-d061-401d7022d8ce",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mido\n",
            "  Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging~=23.1 (from mido)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, mido\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed mido-1.3.2 packaging-23.2\n",
            "Collecting midiutil\n",
            "  Downloading MIDIUtil-1.2.1.tar.gz (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: midiutil\n",
            "  Building wheel for midiutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for midiutil: filename=MIDIUtil-1.2.1-py3-none-any.whl size=54567 sha256=debb425a8e5872770b37845da4635d197da994af6403d7d174a46e828e071272\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/43/4a/00b5e4f2fe5e2cd6e92b461995a3a97a2cebb30ab5783501b0\n",
            "Successfully built midiutil\n",
            "Installing collected packages: midiutil\n",
            "Successfully installed midiutil-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mido\n",
        "!pip install midiutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mido\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib"
      ],
      "metadata": {
        "id": "NBZvuiboUfRb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#midi extraction"
      ],
      "metadata": {
        "id": "yeoYCajsUlsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def midi_to_dataframe(file_path):\n",
        "    mid = mido.MidiFile(file_path)\n",
        "    data = []\n",
        "\n",
        "    for i, track in enumerate(mid.tracks):\n",
        "        absolute_time = 0\n",
        "        for msg in track:\n",
        "            absolute_time += msg.time\n",
        "            if msg.type in ['note_on', 'note_off']:\n",
        "                event = {\n",
        "                    'note': msg.note,\n",
        "                    'file_name': os.path.basename(file_path)\n",
        "                }\n",
        "                data.append(event)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def process_midi_folder(folder_path):\n",
        "    all_data = []\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.mid'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            df = midi_to_dataframe(file_path)\n",
        "            all_data.append(df)\n",
        "\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    return combined_df\n",
        "\n",
        "\n",
        "combined_df = process_midi_folder('midis')\n",
        "\n",
        "combined_df.to_csv('midi.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_ioSy57uUnoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#creating our dataset"
      ],
      "metadata": {
        "id": "Ffjw8eIvWfdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequences(df, sequence_length):\n",
        "    sequences = []\n",
        "    predictions = []\n",
        "    file_names = []\n",
        "\n",
        "    grouped = df.groupby('file_name')\n",
        "\n",
        "    for file_name, group in grouped:\n",
        "        notes = group['note'].tolist()\n",
        "\n",
        "        if len(notes) > sequence_length:\n",
        "            for i in range(len(notes) - sequence_length):\n",
        "                sequences.append(notes[i:i + sequence_length])\n",
        "                predictions.append(notes[i + sequence_length])\n",
        "                file_names.append(file_name)\n",
        "\n",
        "    new_df = pd.DataFrame({'file_name': file_names, 'sequence': sequences, 'prediction': predictions})\n",
        "\n",
        "    return new_df\n",
        "\n",
        "\n",
        "combined_df = pd.read_csv(\"midi.csv\")\n",
        "sequence_length = 5\n",
        "new_df = generate_sequences(combined_df, sequence_length)\n",
        "new_df.to_csv(\"midi_dataset.csv\")"
      ],
      "metadata": {
        "id": "Uov6lFNIVCyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocessing"
      ],
      "metadata": {
        "id": "VaeqHbsZsR01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"midi_dataset.csv\")"
      ],
      "metadata": {
        "id": "pdd_u-X1sTxH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_df(df, scaler_filename='scaler.pkl'):\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    sequences = df['sequence'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "    flattened_sequences = [item for sublist in sequences for item in sublist]\n",
        "    predictions = df['prediction'].tolist()\n",
        "    combined_data = np.array(flattened_sequences + predictions).reshape(-1, 1)\n",
        "\n",
        "    scaler.fit(combined_data)\n",
        "    normalized_combined_data = scaler.transform(combined_data).reshape(-1)\n",
        "\n",
        "    joblib.dump(scaler, scaler_filename)\n",
        "\n",
        "    normalized_sequences = []\n",
        "    index = 0\n",
        "    for seq in sequences:\n",
        "        seq_length = len(seq)\n",
        "        normalized_sequences.append(normalized_combined_data[index:index + seq_length].tolist())\n",
        "        index += seq_length\n",
        "\n",
        "    normalized_predictions = normalized_combined_data[index:index + len(predictions)]\n",
        "\n",
        "    normalized_df = df.copy()\n",
        "    normalized_df['sequence'] = normalized_sequences\n",
        "    normalized_df['prediction'] = normalized_predictions\n",
        "\n",
        "    return normalized_df\n",
        "\n",
        "def denormalize_sequence(normalized_list, scaler_filename='scaler.pkl'):\n",
        "    scaler = joblib.load(scaler_filename)\n",
        "\n",
        "    normalized_array = np.array(normalized_list).reshape(-1, 1)\n",
        "\n",
        "    denormalized_array = scaler.inverse_transform(normalized_array).reshape(-1)\n",
        "\n",
        "    denormalized_array = np.round(denormalized_array).astype(int)\n",
        "\n",
        "    return denormalized_array.tolist()\n",
        "\n",
        "\n",
        "def normalize_sequence(sequence, scaler_filename='scaler.pkl'):\n",
        "    scaler = joblib.load(scaler_filename)\n",
        "\n",
        "    sequence_array = np.array(sequence).reshape(-1, 1)\n",
        "\n",
        "    normalized_sequence = scaler.transform(sequence_array).reshape(-1)\n",
        "\n",
        "    return normalized_sequence.tolist()"
      ],
      "metadata": {
        "id": "1c2jwEfnseSB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df = normalize_df(dataset)"
      ],
      "metadata": {
        "id": "jReSpOFEtVXJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model"
      ],
      "metadata": {
        "id": "a4X7mOF4XeeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "_L5mUN1gW4Zc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    encoder = LabelEncoder()\n",
        "    all_notes = df['sequence'].explode().tolist() + df['prediction'].tolist()\n",
        "    encoder.fit(all_notes)\n",
        "\n",
        "    df['encoded_sequence'] = df['sequence'].apply(lambda seq: encoder.transform(seq))\n",
        "    df['encoded_prediction'] = encoder.transform(df['prediction'])\n",
        "\n",
        "    sequences = np.array(df['encoded_sequence'].tolist())\n",
        "    predictions = np.array(df['encoded_prediction'].tolist())\n",
        "\n",
        "    num_unique_notes = len(encoder.classes_)\n",
        "    sequences = to_categorical(sequences, num_classes=num_unique_notes)\n",
        "    predictions = to_categorical(predictions, num_classes=num_unique_notes)\n",
        "\n",
        "    return sequences, predictions, encoder\n",
        "\n",
        "def create_model_demo(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_demo2(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(256, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(128))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Adding early stopping\n",
        "    #early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_next_note(model, input_sequence, encoder):\n",
        "    num_unique_notes = len(encoder.classes_)\n",
        "    input_sequence = to_categorical(input_sequence, num_classes=num_unique_notes)\n",
        "    input_sequence = np.expand_dims(input_sequence, axis=0)\n",
        "\n",
        "    prediction = model.predict(input_sequence)\n",
        "    predicted_note = encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "    note = denormalize_sequence(predicted_note[0])\n",
        "\n",
        "    return note[0]\n",
        "\n",
        "def predict_next_note1(model, input_sequence, encoder):\n",
        "    num_unique_notes = len(encoder.classes_)\n",
        "    input_sequence_encoded = encoder.transform(input_sequence)\n",
        "    input_sequence_encoded = np.array(input_sequence_encoded)\n",
        "    input_sequence_encoded = input_sequence_encoded.reshape(1, -1)\n",
        "    input_sequence_encoded = to_categorical(input_sequence_encoded, num_classes=num_unique_notes)\n",
        "\n",
        "\n",
        "    prediction = model.predict(input_sequence_encoded)\n",
        "    next_note_index = np.argmax(prediction)\n",
        "\n",
        "    next_note = encoder.inverse_transform([next_note_index])[0]\n",
        "\n",
        "\n",
        "\n",
        "    note = denormalize_sequence([next_note])\n",
        "\n",
        "\n",
        "    return note[0]\n",
        "\n",
        "\n",
        "\n",
        "def predict_next_note2(model, input_sequence, encoder):\n",
        "    num_unique_notes = len(encoder.classes_)\n",
        "    input_sequence_encoded = encoder.transform(input_sequence)\n",
        "    input_sequence_encoded = np.array(input_sequence_encoded)\n",
        "    input_sequence_encoded = input_sequence_encoded.reshape(1, -1)\n",
        "    input_sequence_encoded = to_categorical(input_sequence_encoded, num_classes=num_unique_notes)\n",
        "\n",
        "\n",
        "    prediction = model.predict(input_sequence_encoded)\n",
        "    next_note_index = np.argmax(prediction)\n",
        "\n",
        "    next_note = encoder.inverse_transform([next_note_index])[0]\n",
        "\n",
        "    return next_note\n",
        "\n",
        "def generate_notes(model, initial_sequence, num_notes,encoder):\n",
        "\n",
        "  initial_sequence = normalize_sequence(initial_sequence)\n",
        "  notes = initial_sequence\n",
        "\n",
        "  while len(notes) < num_notes  :\n",
        "\n",
        "    new_note = predict_next_note2(model, notes[-5:], encoder)\n",
        "    notes.append(new_note)\n",
        "\n",
        "  return denormalize_sequence(notes)\n"
      ],
      "metadata": {
        "id": "yzgtKkluYR6V"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequences, predictions, encoder = preprocess_data(normalized_df)\n",
        "input_shape = (sequences.shape[1], sequences.shape[2])\n",
        "num_classes = predictions.shape[1]\n",
        "\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.fit(sequences, predictions, epochs=135, batch_size=64)\n",
        "model.save('note_prediction_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "RjDDgkQpYdcm",
        "outputId": "f6bcf7a3-5910-45c0-f76a-6f4b80060ed9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/135\n",
            "120/120 [==============================] - 6s 6ms/step - loss: 3.8908\n",
            "Epoch 2/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 3.4631\n",
            "Epoch 3/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 3.2616\n",
            "Epoch 4/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 3.1397\n",
            "Epoch 5/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 3.0459\n",
            "Epoch 6/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 2.9610\n",
            "Epoch 7/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.8773\n",
            "Epoch 8/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.8077\n",
            "Epoch 9/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.7173\n",
            "Epoch 10/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.6386\n",
            "Epoch 11/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.5778\n",
            "Epoch 12/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 2.5030\n",
            "Epoch 13/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 2.4546\n",
            "Epoch 14/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.3835\n",
            "Epoch 15/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.3289\n",
            "Epoch 16/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.2708\n",
            "Epoch 17/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.2090\n",
            "Epoch 18/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 2.1538\n",
            "Epoch 19/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.1081\n",
            "Epoch 20/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 2.0463\n",
            "Epoch 21/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.9969\n",
            "Epoch 22/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.9319\n",
            "Epoch 23/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.8748\n",
            "Epoch 24/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.8359\n",
            "Epoch 25/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.7863\n",
            "Epoch 26/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.7367\n",
            "Epoch 27/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.6877\n",
            "Epoch 28/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.6582\n",
            "Epoch 29/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.5963\n",
            "Epoch 30/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.5529\n",
            "Epoch 31/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.5157\n",
            "Epoch 32/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.4700\n",
            "Epoch 33/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.4265\n",
            "Epoch 34/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.3753\n",
            "Epoch 35/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.3519\n",
            "Epoch 36/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.3184\n",
            "Epoch 37/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.2656\n",
            "Epoch 38/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.2306\n",
            "Epoch 39/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.2098\n",
            "Epoch 40/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.1617\n",
            "Epoch 41/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.1428\n",
            "Epoch 42/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.0986\n",
            "Epoch 43/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 1.0689\n",
            "Epoch 44/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.0409\n",
            "Epoch 45/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 1.0188\n",
            "Epoch 46/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.9882\n",
            "Epoch 47/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.9637\n",
            "Epoch 48/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.9382\n",
            "Epoch 49/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.9099\n",
            "Epoch 50/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.8925\n",
            "Epoch 51/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.8660\n",
            "Epoch 52/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.8392\n",
            "Epoch 53/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.8173\n",
            "Epoch 54/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.7982\n",
            "Epoch 55/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.7641\n",
            "Epoch 56/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.7553\n",
            "Epoch 57/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.7356\n",
            "Epoch 58/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.7171\n",
            "Epoch 59/135\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.7020\n",
            "Epoch 60/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.6840\n",
            "Epoch 61/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6602\n",
            "Epoch 62/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.6459\n",
            "Epoch 63/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6346\n",
            "Epoch 64/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.6086\n",
            "Epoch 65/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.6035\n",
            "Epoch 66/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.5807\n",
            "Epoch 67/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5724\n",
            "Epoch 68/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.5675\n",
            "Epoch 69/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.5394\n",
            "Epoch 70/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.5266\n",
            "Epoch 71/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5145\n",
            "Epoch 72/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.5112\n",
            "Epoch 73/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4918\n",
            "Epoch 74/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.4915\n",
            "Epoch 75/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.4878\n",
            "Epoch 76/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.4590\n",
            "Epoch 77/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.4665\n",
            "Epoch 78/135\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.4530\n",
            "Epoch 79/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.4405\n",
            "Epoch 80/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4328\n",
            "Epoch 81/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4213\n",
            "Epoch 82/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.4155\n",
            "Epoch 83/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.4171\n",
            "Epoch 84/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3972\n",
            "Epoch 85/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.4009\n",
            "Epoch 86/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3926\n",
            "Epoch 87/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3804\n",
            "Epoch 88/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3740\n",
            "Epoch 89/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3756\n",
            "Epoch 90/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3575\n",
            "Epoch 91/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3620\n",
            "Epoch 92/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3653\n",
            "Epoch 93/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3459\n",
            "Epoch 94/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.3364\n",
            "Epoch 95/135\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.3297\n",
            "Epoch 96/135\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.3362\n",
            "Epoch 97/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3315\n",
            "Epoch 98/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3367\n",
            "Epoch 99/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3246\n",
            "Epoch 100/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3103\n",
            "Epoch 101/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3112\n",
            "Epoch 102/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3083\n",
            "Epoch 103/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3164\n",
            "Epoch 104/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3045\n",
            "Epoch 105/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3164\n",
            "Epoch 106/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3072\n",
            "Epoch 107/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2883\n",
            "Epoch 108/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3032\n",
            "Epoch 109/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.3036\n",
            "Epoch 110/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.3095\n",
            "Epoch 111/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2826\n",
            "Epoch 112/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2799\n",
            "Epoch 113/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2798\n",
            "Epoch 114/135\n",
            "120/120 [==============================] - 1s 8ms/step - loss: 0.2798\n",
            "Epoch 115/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2742\n",
            "Epoch 116/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2730\n",
            "Epoch 117/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2714\n",
            "Epoch 118/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2744\n",
            "Epoch 119/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2748\n",
            "Epoch 120/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2674\n",
            "Epoch 121/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2597\n",
            "Epoch 122/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2540\n",
            "Epoch 123/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2656\n",
            "Epoch 124/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2528\n",
            "Epoch 125/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2593\n",
            "Epoch 126/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2485\n",
            "Epoch 127/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2431\n",
            "Epoch 128/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2448\n",
            "Epoch 129/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2489\n",
            "Epoch 130/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2440\n",
            "Epoch 131/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2505\n",
            "Epoch 132/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2411\n",
            "Epoch 133/135\n",
            "120/120 [==============================] - 1s 7ms/step - loss: 0.2469\n",
            "Epoch 134/135\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 0.2504\n",
            "Epoch 135/135\n",
            "120/120 [==============================] - 1s 5ms/step - loss: 0.2299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#usage"
      ],
      "metadata": {
        "id": "8-1U9ydWZ8JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('note_prediction_model.h5')\n",
        "input_sequence = [46, 58, 62, 65, 69]\n",
        "input_sequence = normalize_sequence(input_sequence)\n",
        "predicted_note = predict_next_note1(loaded_model, input_sequence, encoder)\n",
        "print(f\"The predicted next note is: {predicted_note}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vWUzGQ7VZ5iC",
        "outputId": "21ff13da-ab01-492f-946e-b5e5f2ccf5fa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 602ms/step\n",
            "The predicted next note is: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_sequence = [75, 77, 77, 80, 46]\n",
        "num_notes_needed = 50\n",
        "\n",
        "\n",
        "generated_notes = generate_notes(loaded_model, initial_sequence, num_notes_needed,encoder)\n",
        "print(f\"Generated sequence: {generated_notes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CXwRJfZlapin",
        "outputId": "e5044039-23d2-4a85-d3c6-f7ee7c3c0904"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Generated sequence: [75, 77, 77, 80, 46, 80, 77, 49, 77, 49, 70, 73, 49, 73, 70, 80, 49, 80, 77, 51, 77, 75, 75, 77, 77, 75, 51, 75, 73, 51, 73, 72, 51, 72, 72, 56, 72, 68, 68, 70, 70, 72, 56, 72, 73, 56, 73, 75, 56, 75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convert notes to midi"
      ],
      "metadata": {
        "id": "3VfTYQiDnVme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from midiutil.MidiFile import MIDIFile"
      ],
      "metadata": {
        "id": "s8UAsE3inkR-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def notes_to_midi(note_numbers, output_file='output.mid', tempo=120):\n",
        "\n",
        "    midi = MIDIFile(1)\n",
        "\n",
        "\n",
        "    track = 0\n",
        "    midi.addTrackName(track, 0, \"Sample Track\")\n",
        "    midi.addTempo(track, 0, tempo)\n",
        "\n",
        "\n",
        "    time = 0\n",
        "    for note_number in note_numbers:\n",
        "\n",
        "        midi.addNote(track, 0, note_number, time, 1, 100)\n",
        "        time += 1\n",
        "\n",
        "    with open(output_file, 'wb') as f:\n",
        "        midi.writeFile(f)\n",
        "\n",
        "    print(f\"MIDI file generated: {output_file}\")\n"
      ],
      "metadata": {
        "id": "Ez65za_AnXqU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "notes_to_midi(generated_notes, output_file='output.mid')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G_E_udUpnnkc",
        "outputId": "940b1406-96ad-43f5-c750-f324acedc54a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIDI file generated: output.mid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#to save notebook"
      ],
      "metadata": {
        "id": "4m8yjyRG0_Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert\n",
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "!jupyter nbconvert --to pdf \"/content/drive/MyDrive/Colab Notebooks/ml_midi_maker.ipynb\"\n"
      ],
      "metadata": {
        "id": "eoEBaZPc1Cd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}